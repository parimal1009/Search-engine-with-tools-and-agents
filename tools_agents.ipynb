{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv research\n",
    "##Tools creation\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun,ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from wikipedia) (4.13.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#used inbuilt tool of wikipedia\n",
    "# Initialize the Wikipedia API Wrapper\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "\n",
    "# Create the Wikipedia query chain\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "\n",
    "wiki.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_result=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "##custom tools \n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parim\\AppData\\Local\\Temp\\ipykernel_7516\\3568925258.py:7: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  ollama_embeddings = OllamaEmbeddings(model=\"deepseek-r1:14b\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'OllamaEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A51108C1F0> search_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings  # Correct import for Ollama\n",
    "\n",
    "# Initialize Ollama embeddings with the deepseek model\n",
    "ollama_embeddings = OllamaEmbeddings(model=\"deepseek-r1:14b\")\n",
    "\n",
    "# Load documents from a webpage\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split documents into smaller chunks for embedding\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "# Create a FAISS vector database using Ollama embeddings\n",
    "vectordb = FAISS.from_documents(documents, ollama_embeddings)\n",
    "\n",
    "# Create a retriever to fetch relevant documents\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "# Print the retriever object to check if it's working\n",
    "print(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith-search\",\"Search any information about Langsmith \")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\parim\\\\GENAIML\\\\Langchain\\\\langchain_projects\\\\QnA_chatbot\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langsmith-search', description='Search any information about Langsmith ', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001A570780AF0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A51108C1F0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001A570AD09D0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A51108C1F0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tools and agents with llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Using cached langchain_groq-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.42 (from langchain_groq)\n",
      "  Using cached langchain_core-0.3.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Using cached groq-0.19.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_groq) (0.3.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_groq) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_groq) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_groq) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_groq) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parim\\genaiml\\langchain\\langchain_projects\\qna_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_groq) (2.3.0)\n",
      "Using cached langchain_groq-0.2.5-py3-none-any.whl (15 kB)\n",
      "Using cached groq-0.19.0-py3-none-any.whl (122 kB)\n",
      "Using cached langchain_core-0.3.44-py3-none-any.whl (415 kB)\n",
      "Installing collected packages: groq, langchain-core, langchain_groq\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.33\n",
      "    Uninstalling langchain-core-0.3.33:\n",
      "      Successfully uninstalled langchain-core-0.3.33\n",
      "Successfully installed groq-0.19.0 langchain-core-0.3.44 langchain_groq-0.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run all this tools with Agents and LLM Models\n",
    "\n",
    "## Tools, LLM-->AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "from langchain import hub\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001A56FD28B80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001A56FD28B80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001A5A01E82B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001A5A01E9660>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith ', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001A56FD28B80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001A56FD28B80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001A5A01E82B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001A5A01E9660>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith ', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\parim\\\\GENAIML\\\\Langchain\\\\langchain_projects\\\\QnA_chatbot\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith-search', description='Search any information about Langsmith ', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001A570780AF0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A51108C1F0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001A570AD09D0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A51108C1F0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"what is machine learning\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
